We next use our language model to select the most likely path, which will hopefully be a well-formed natural language utterance that a person will find easy to remember. Because our lattice in this case is far from a freeform graph, we used its structure to speed up computation. For this simplest of cases, where the lattice is simply a table of word lists, we did the obvious thing. We kept the N most probable paths in a priority heap, and processed the levels of the lattice one at a time, trying each potential word with each path so far, scoring the new extended paths and remembering the best N of those. We avoided generating the lattice a priori, instead having a list of constraints along which our search advanced. Given the lexicon, our current constraint (e.g. the word must begin with ‘a’, have three syllables, and rhyme with ‘-ing’) would return to us a list of candidate words.