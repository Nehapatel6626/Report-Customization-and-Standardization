cross validation number equal to 2, the number of total errors is higher than for a single simple tree.  This is a property of the data set.  When the data set is split randomly, it could happen that split sets are not representative of the domain.  It should also be noted that the number of examples that a cross validation tree trains upon is fewer than the normal tree.  This is due to the fact that we have to set aside a portion of the training data for testing during the cross validation process.  The second irregularity occurs when cross validation number is equal to 12.  This performs worse than with cross validation number equal to 10.  This again is attributed to the random splitting of the data set.  This random splitting in cross validation can lead to a small increase in the total number of errors.  But from our experimentation, we observed that such increases in misclassifications are small in magnitude and are rid off when the cross validation number is increased further.