trend to note is that of the reducing number of total errors.  When ensemble number is less than or equal to 4, there are an insufficient number of trees for the ensemble to make a difference.  This is due to the large number of trees required in order to correctly classify a hard-to-learn example.  This is why the normal decision tree and the ensemble have identical performance till ensemble number 4. After 8 trees in the ensemble, the total number of errors remains constant.  This indicates either one of two possible scenarios.  One possibility is that the remaining misclassified examples are very difficult; hence require a large number of trees.  This is not likely, since even with 16 trees no difference is observed.  The second possibility can be due to outliers in the data set and other sorts of inconsistencies in the dataset which make fault-free prediction difficult.